{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing the libs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbbea7b84dcc0a11"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:52:54.018648Z",
     "start_time": "2024-04-04T08:52:52.653976Z"
    }
   },
   "id": "a4e27b4356ff7341",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing the datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76ea51b02de6a10b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We won't be using this dataset.\n",
    "movies = pd.read_csv('data/ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('data/ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('data/ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:52:56.625173Z",
     "start_time": "2024-04-04T08:52:54.019956Z"
    }
   },
   "id": "209e1c040acc67c9",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare the training & test sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2df86c45a5f1a22e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('data/ml-100k/u1.base', delimiter = '\\t')\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "test_set = pd.read_csv('data/ml-100k/u1.test', delimiter = '\\t')\n",
    "test_set = np.array(test_set, dtype = 'int')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:52:56.650830Z",
     "start_time": "2024-04-04T08:52:56.626140Z"
    }
   },
   "id": "9833a02639d392ee",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get the number of users and movies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec1542e9533577af"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "943"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n",
    "nb_users"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:52:56.658672Z",
     "start_time": "2024-04-04T08:52:56.651813Z"
    }
   },
   "id": "d8e98ca33ed6acd5",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1682"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))\n",
    "nb_movies"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:52:56.666404Z",
     "start_time": "2024-04-04T08:52:56.660364Z"
    }
   },
   "id": "d676f6d28ced2502",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Converting & preparing data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54c3621fa4a81da8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "  new_data = []\n",
    "  for id_users in range(1, nb_users + 1):\n",
    "      \n",
    "    # Get the current user's movie ids\n",
    "    id_movies = data[:, 1][data[:, 0] == id_users]\n",
    "    \n",
    "    # Get the current user's rating scores \n",
    "    id_ratings = data[:, 2][data[:, 0] == id_users]\n",
    "    \n",
    "    ratings = np.zeros(nb_movies)\n",
    "    # Assign the ratings to movies, which they belong\n",
    "    ratings[id_movies - 1] = id_ratings\n",
    "    new_data.append(list(ratings))\n",
    "  return new_data\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:52:56.853267Z",
     "start_time": "2024-04-04T08:52:56.667259Z"
    }
   },
   "id": "a1c3eb00ab75c7e2",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert data to tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d34485b87a355fe6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 3., 4.,  ..., 0., 0., 0.],\n        [4., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [5., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 5., 0.,  ..., 0., 0., 0.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "training_set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:52:56.944795Z",
     "start_time": "2024-04-04T08:52:56.854224Z"
    }
   },
   "id": "396e6bc4b9baf998",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = torch.FloatTensor(test_set)\n",
    "test_set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:52:57.039656Z",
     "start_time": "2024-04-04T08:52:56.945460Z"
    }
   },
   "id": "25642c60dc95fd46",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the SAE Class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67f91211aae6f77"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We need to create a class to specify and define the behaviours of our AE (to give instructions)\n",
    "# Object of this class will be an AE\n",
    "# Inheritance to use all the functions of the parent class\n",
    "# SAE -> Stacked Auto Encoders\n",
    "# We have several hidden layers -> several encodings of the input vector features\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, ): # Put nothing after the comma, because we have inheritance\n",
    "        super(SAE, self).__init__() # Get the functions/methods of the module\n",
    "        ## nn is module, Linear and Sigmoid are classes of the nn module\n",
    "        self.fc1 = nn.Linear(nb_movies, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, nb_movies)\n",
    "        # The next function get the output of the last function as input\n",
    "        # nb_movies - 20neuron - 10neuron - 20 neuron - nb_movies -> these are the layers\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:52:57.043275Z",
     "start_time": "2024-04-04T08:52:57.040489Z"
    }
   },
   "id": "883a6ca0f0d0bae4",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create instances and define parameters\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:52:57.463860Z",
     "start_time": "2024-04-04T08:52:57.044030Z"
    }
   },
   "id": "a003d7c949af92c1",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26feeae0910e538e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define number of epoch\n",
    "nb_epoch = 200"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:52:57.466237Z",
     "start_time": "2024-04-04T08:52:57.464746Z"
    }
   },
   "id": "20740313d36f931e",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :1 loss: tensor(1.7713)\n",
      "epoch :2 loss: tensor(1.0968)\n",
      "epoch :3 loss: tensor(1.0533)\n",
      "epoch :4 loss: tensor(1.0381)\n",
      "epoch :5 loss: tensor(1.0310)\n",
      "epoch :6 loss: tensor(1.0264)\n",
      "epoch :7 loss: tensor(1.0240)\n",
      "epoch :8 loss: tensor(1.0219)\n",
      "epoch :9 loss: tensor(1.0209)\n",
      "epoch :10 loss: tensor(1.0193)\n",
      "epoch :11 loss: tensor(1.0191)\n",
      "epoch :12 loss: tensor(1.0185)\n",
      "epoch :13 loss: tensor(1.0181)\n",
      "epoch :14 loss: tensor(1.0176)\n",
      "epoch :15 loss: tensor(1.0174)\n",
      "epoch :16 loss: tensor(1.0169)\n",
      "epoch :17 loss: tensor(1.0168)\n",
      "epoch :18 loss: tensor(1.0164)\n",
      "epoch :19 loss: tensor(1.0165)\n",
      "epoch :20 loss: tensor(1.0160)\n",
      "epoch :21 loss: tensor(1.0165)\n",
      "epoch :22 loss: tensor(1.0157)\n",
      "epoch :23 loss: tensor(1.0160)\n",
      "epoch :24 loss: tensor(1.0157)\n",
      "epoch :25 loss: tensor(1.0156)\n",
      "epoch :26 loss: tensor(1.0156)\n",
      "epoch :27 loss: tensor(1.0153)\n",
      "epoch :28 loss: tensor(1.0153)\n",
      "epoch :29 loss: tensor(1.0137)\n",
      "epoch :30 loss: tensor(1.0119)\n",
      "epoch :31 loss: tensor(1.0096)\n",
      "epoch :32 loss: tensor(1.0098)\n",
      "epoch :33 loss: tensor(1.0052)\n",
      "epoch :34 loss: tensor(1.0057)\n",
      "epoch :35 loss: tensor(1.0009)\n",
      "epoch :36 loss: tensor(1.0008)\n",
      "epoch :37 loss: tensor(0.9974)\n",
      "epoch :38 loss: tensor(0.9956)\n",
      "epoch :39 loss: tensor(0.9958)\n",
      "epoch :40 loss: tensor(0.9915)\n",
      "epoch :41 loss: tensor(0.9899)\n",
      "epoch :42 loss: tensor(0.9871)\n",
      "epoch :43 loss: tensor(0.9915)\n",
      "epoch :44 loss: tensor(0.9913)\n",
      "epoch :45 loss: tensor(0.9874)\n",
      "epoch :46 loss: tensor(0.9853)\n",
      "epoch :47 loss: tensor(0.9811)\n",
      "epoch :48 loss: tensor(0.9836)\n",
      "epoch :49 loss: tensor(0.9788)\n",
      "epoch :50 loss: tensor(0.9795)\n",
      "epoch :51 loss: tensor(0.9803)\n",
      "epoch :52 loss: tensor(0.9752)\n",
      "epoch :53 loss: tensor(0.9767)\n",
      "epoch :54 loss: tensor(0.9732)\n",
      "epoch :55 loss: tensor(0.9698)\n",
      "epoch :56 loss: tensor(0.9668)\n",
      "epoch :57 loss: tensor(0.9656)\n",
      "epoch :58 loss: tensor(0.9677)\n",
      "epoch :59 loss: tensor(0.9650)\n",
      "epoch :60 loss: tensor(0.9645)\n",
      "epoch :61 loss: tensor(0.9619)\n",
      "epoch :62 loss: tensor(0.9628)\n",
      "epoch :63 loss: tensor(0.9643)\n",
      "epoch :64 loss: tensor(0.9682)\n",
      "epoch :65 loss: tensor(0.9600)\n",
      "epoch :66 loss: tensor(0.9599)\n",
      "epoch :67 loss: tensor(0.9602)\n",
      "epoch :68 loss: tensor(0.9653)\n",
      "epoch :69 loss: tensor(0.9610)\n",
      "epoch :70 loss: tensor(0.9554)\n",
      "epoch :71 loss: tensor(0.9550)\n",
      "epoch :72 loss: tensor(0.9536)\n",
      "epoch :73 loss: tensor(0.9525)\n",
      "epoch :74 loss: tensor(0.9512)\n",
      "epoch :75 loss: tensor(0.9505)\n",
      "epoch :76 loss: tensor(0.9497)\n",
      "epoch :77 loss: tensor(0.9489)\n",
      "epoch :78 loss: tensor(0.9484)\n",
      "epoch :79 loss: tensor(0.9469)\n",
      "epoch :80 loss: tensor(0.9474)\n",
      "epoch :81 loss: tensor(0.9461)\n",
      "epoch :82 loss: tensor(0.9468)\n",
      "epoch :83 loss: tensor(0.9458)\n",
      "epoch :84 loss: tensor(0.9455)\n",
      "epoch :85 loss: tensor(0.9435)\n",
      "epoch :86 loss: tensor(0.9440)\n",
      "epoch :87 loss: tensor(0.9429)\n",
      "epoch :88 loss: tensor(0.9435)\n",
      "epoch :89 loss: tensor(0.9423)\n",
      "epoch :90 loss: tensor(0.9424)\n",
      "epoch :91 loss: tensor(0.9421)\n",
      "epoch :92 loss: tensor(0.9439)\n",
      "epoch :93 loss: tensor(0.9519)\n",
      "epoch :94 loss: tensor(0.9467)\n",
      "epoch :95 loss: tensor(0.9459)\n",
      "epoch :96 loss: tensor(0.9453)\n",
      "epoch :97 loss: tensor(0.9441)\n",
      "epoch :98 loss: tensor(0.9434)\n",
      "epoch :99 loss: tensor(0.9440)\n",
      "epoch :100 loss: tensor(0.9428)\n",
      "epoch :101 loss: tensor(0.9417)\n",
      "epoch :102 loss: tensor(0.9419)\n",
      "epoch :103 loss: tensor(0.9398)\n",
      "epoch :104 loss: tensor(0.9402)\n",
      "epoch :105 loss: tensor(0.9427)\n",
      "epoch :106 loss: tensor(0.9377)\n",
      "epoch :107 loss: tensor(0.9374)\n",
      "epoch :108 loss: tensor(0.9411)\n",
      "epoch :109 loss: tensor(0.9426)\n",
      "epoch :110 loss: tensor(0.9412)\n",
      "epoch :111 loss: tensor(0.9398)\n",
      "epoch :112 loss: tensor(0.9388)\n",
      "epoch :113 loss: tensor(0.9373)\n",
      "epoch :114 loss: tensor(0.9383)\n",
      "epoch :115 loss: tensor(0.9370)\n",
      "epoch :116 loss: tensor(0.9375)\n",
      "epoch :117 loss: tensor(0.9365)\n",
      "epoch :118 loss: tensor(0.9375)\n",
      "epoch :119 loss: tensor(0.9357)\n",
      "epoch :120 loss: tensor(0.9356)\n",
      "epoch :121 loss: tensor(0.9352)\n",
      "epoch :122 loss: tensor(0.9349)\n",
      "epoch :123 loss: tensor(0.9349)\n",
      "epoch :124 loss: tensor(0.9345)\n",
      "epoch :125 loss: tensor(0.9341)\n",
      "epoch :126 loss: tensor(0.9340)\n",
      "epoch :127 loss: tensor(0.9328)\n",
      "epoch :128 loss: tensor(0.9329)\n",
      "epoch :129 loss: tensor(0.9327)\n",
      "epoch :130 loss: tensor(0.9443)\n",
      "epoch :131 loss: tensor(0.9425)\n",
      "epoch :132 loss: tensor(0.9374)\n",
      "epoch :133 loss: tensor(0.9349)\n",
      "epoch :134 loss: tensor(0.9355)\n",
      "epoch :135 loss: tensor(0.9355)\n",
      "epoch :136 loss: tensor(0.9330)\n",
      "epoch :137 loss: tensor(0.9313)\n",
      "epoch :138 loss: tensor(0.9323)\n",
      "epoch :139 loss: tensor(0.9307)\n",
      "epoch :140 loss: tensor(0.9319)\n",
      "epoch :141 loss: tensor(0.9301)\n",
      "epoch :142 loss: tensor(0.9309)\n",
      "epoch :143 loss: tensor(0.9290)\n",
      "epoch :144 loss: tensor(0.9287)\n",
      "epoch :145 loss: tensor(0.9278)\n",
      "epoch :146 loss: tensor(0.9303)\n",
      "epoch :147 loss: tensor(0.9271)\n",
      "epoch :148 loss: tensor(0.9275)\n",
      "epoch :149 loss: tensor(0.9267)\n",
      "epoch :150 loss: tensor(0.9271)\n",
      "epoch :151 loss: tensor(0.9255)\n",
      "epoch :152 loss: tensor(0.9263)\n",
      "epoch :153 loss: tensor(0.9284)\n",
      "epoch :154 loss: tensor(0.9278)\n",
      "epoch :155 loss: tensor(0.9262)\n",
      "epoch :156 loss: tensor(0.9270)\n",
      "epoch :157 loss: tensor(0.9253)\n",
      "epoch :158 loss: tensor(0.9265)\n",
      "epoch :159 loss: tensor(0.9246)\n",
      "epoch :160 loss: tensor(0.9254)\n",
      "epoch :161 loss: tensor(0.9240)\n",
      "epoch :162 loss: tensor(0.9244)\n",
      "epoch :163 loss: tensor(0.9308)\n",
      "epoch :164 loss: tensor(0.9330)\n",
      "epoch :165 loss: tensor(0.9289)\n",
      "epoch :166 loss: tensor(0.9323)\n",
      "epoch :167 loss: tensor(0.9318)\n",
      "epoch :168 loss: tensor(0.9328)\n",
      "epoch :169 loss: tensor(0.9381)\n",
      "epoch :170 loss: tensor(0.9417)\n",
      "epoch :171 loss: tensor(0.9315)\n",
      "epoch :172 loss: tensor(0.9289)\n",
      "epoch :173 loss: tensor(0.9278)\n",
      "epoch :174 loss: tensor(0.9285)\n",
      "epoch :175 loss: tensor(0.9260)\n",
      "epoch :176 loss: tensor(0.9273)\n",
      "epoch :177 loss: tensor(0.9251)\n",
      "epoch :178 loss: tensor(0.9267)\n",
      "epoch :179 loss: tensor(0.9263)\n",
      "epoch :180 loss: tensor(0.9262)\n",
      "epoch :181 loss: tensor(0.9239)\n",
      "epoch :182 loss: tensor(0.9241)\n",
      "epoch :183 loss: tensor(0.9217)\n",
      "epoch :184 loss: tensor(0.9230)\n",
      "epoch :185 loss: tensor(0.9213)\n",
      "epoch :186 loss: tensor(0.9214)\n",
      "epoch :187 loss: tensor(0.9214)\n",
      "epoch :188 loss: tensor(0.9206)\n",
      "epoch :189 loss: tensor(0.9204)\n",
      "epoch :190 loss: tensor(0.9207)\n",
      "epoch :191 loss: tensor(0.9198)\n",
      "epoch :192 loss: tensor(0.9199)\n",
      "epoch :193 loss: tensor(0.9188)\n",
      "epoch :194 loss: tensor(0.9185)\n",
      "epoch :195 loss: tensor(0.9171)\n",
      "epoch :196 loss: tensor(0.9177)\n",
      "epoch :197 loss: tensor(0.9165)\n",
      "epoch :198 loss: tensor(0.9176)\n",
      "epoch :199 loss: tensor(0.9160)\n",
      "epoch :200 loss: tensor(0.9159)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    \n",
    "    #we will use RMSE at the end and RMSE is a float. That's why we use float \n",
    "    s = 0. # number of users who rated at least one movie\n",
    "    \n",
    "    for id_user in range (nb_users):\n",
    "        \n",
    "        # Add a fake dimension for functions\n",
    "        # index of fake dimension is 0\n",
    "        # we create batch\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        \n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data>0) > 0:\n",
    "            output = sae(input)\n",
    "            # GD won't be computed in target, it'll computed just in input vector\n",
    "            target.require_grad = False\n",
    "            \n",
    "            # zero values don't have impact on the update of the different weights\n",
    "            # before the loss we make them 0 to save comp power\n",
    "            output[target == 0] = 0 \n",
    "            \n",
    "            # calculate the loss func.\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # number of all movies divided by number of rated movies\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data>0) + 1e-10)\n",
    "            \n",
    "            # increase or decrease the weights? ->backward method\n",
    "            # direction of the optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            # loss data is the square error, that's why we take sqrt to get one degree loss\n",
    "            train_loss  += np.sqrt(loss.data*mean_corrector)\n",
    "            \n",
    "            # if user rated, increase s\n",
    "            s += 1.\n",
    "            \n",
    "            \n",
    "            optimizer.step() # intensity/amount of the updates\n",
    "    print('epoch :' + str(epoch) + ' loss: ' + str(train_loss/s))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:55:10.448712Z",
     "start_time": "2024-04-04T08:52:57.466834Z"
    }
   },
   "id": "eb0cc519aeb43a49",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing the SAE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "595d3799c300dc09"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.9585)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "#we will use RMSE at the end and RMSE is a float. That's why we use float \n",
    "s = 0. # number of users who rated at least one movie\n",
    "for id_user in range(nb_users):\n",
    "    # Add a fake dimension for functions\n",
    "    # index of fake dimension is 0\n",
    "    # we create batch\n",
    "  input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "  target = Variable(test_set[id_user]).unsqueeze(0) \n",
    "  if torch.sum(target.data > 0) > 0:\n",
    "    output = sae(input)\n",
    "    # GD won't be computed in target, it'll computed just in input vector\n",
    "    target.require_grad = False\n",
    "    # zero values don't have impact on the update of the different weights\n",
    "    # before the loss we make them 0 to save comp power\n",
    "    output[target == 0] = 0\n",
    "    # calculate the loss func.\n",
    "    loss = criterion(output, target)\n",
    "    # number of all movies divided by number of rated movies\n",
    "    mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "    # loss data is the square error, that's why we take sqrt to get one degree loss\n",
    "    test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "    # if user rated, increase s\n",
    "    s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:55:10.511904Z",
     "start_time": "2024-04-04T08:55:10.449789Z"
    }
   },
   "id": "557fe3e2f49f9fac",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T08:55:10.516702Z",
     "start_time": "2024-04-04T08:55:10.515224Z"
    }
   },
   "id": "e783c967b15a328f",
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
